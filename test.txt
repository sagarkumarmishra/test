import requests

DATAHUB_URL = "https://dhub-ui-int.cta.allianz/actuator/health"

try:
    response = requests.get(DATAHUB_URL, timeout=10)
    print("Connected successfully")
    print("Status Code:", response.status_code)
    print("Response:", response.text)
except Exception as e:
    print("Connection failed")
    print(e)
Here‚Äôs a **very short and clean** version you can use üëá

> Tested ADP ‚Üí DataHub from Azure Synapse INT.
> Browser access works, but Synapse fails with **DNS resolution error**, indicating a network/DNS restriction.
> Network access from Synapse INT to DataHub INT is required to proceed.


MariaXavier.Mariappan@bs.nttdata.com

10147514


The employee is involved in data processing, system integration, and analytics-related activities, supporting business operations through ETL processes, reporting, and technology-driven insights.



import requests

url = "https://dhub-ui-int.cta.allianz/api/your-endpoint"

headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer <TOKEN>"
}

payload = {
    "portfolioId": "123",
    "data": "test"
}

response = requests.post(url, json=payload, headers=headers, timeout=30)

print(response.status_code)
print(response.text)




import requests

try:
    response = requests.get("https://www.google.com", timeout=10)
    print("Public internet WORKS! Status:", response.status_code)
    print("Snippet:", response.text[:200])
except Exception as e:
    print("Public outbound also fails:", str(e))





import requests

url = "https://dhub-ui-int.cta.allianz/actuator/health"

response = requests.get(url, timeout=30)

print("Status code:", response.status_code)
print("Response:", response.text)





import requests

url = "https://dhub-ui-int.cta.allianz/api/v1/ingestion"

headers = {
    "Authorization": "Bearer <ACCESS_TOKEN>",
    "Content-Type": "application/json"
}

payload = {
    "source": "synapse",
    "dataset": "test",
    "records": 1
}

response = requests.post(url, headers=headers, json=payload)

print(response.status_code)
print(response.text)



import socket

try:
    print(socket.gethostbyname("dhub-ui-int.cta.allianz"))
except Exception as e:
    print("DNS failed:", e)



import requests

url = "https://dhub-int.cta.allianz/api/v1/ingestion"

headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer <YOUR_TOKEN_IF_REQUIRED>"
}

payload = {
    "message": "hello from synapse python"
}

response = requests.post(
    url,
    json=payload,
    headers=headers,
    timeout=30
)

print("Status code:", response.status_code)
print("Response:", response.text)




import socket
socket.gethostbyname("dhub-int.cta.allianz")




import requests
import socket

URL = "https://dhub-int.cta.allianz/actuator/health"

print("Testing DNS resolution...")
try:
    print("IP:", socket.gethostbyname("dhub-int.cta.allianz"))
except Exception as e:
    print("‚ùå DNS FAILED:", e)

print("\nCalling DataHub API...")
try:
    r = requests.get(URL, timeout=10)
    print("‚úÖ Connected")
    print("Status Code:", r.status_code)
    print("Response:", r.text)
except Exception as e:
    print("‚ùå API Call Failed")
    print(e)


"C:\Program Files\Python314\python.exe" -m pip install requests

"C:\Program Files\Python314\python.exe" -m ensurepip --upgrade

py "C:\Users\esit6ay\OneDrive - Allianz\Desktop\test.py"


"C:\Program Files\Python314\python.exe" -c "import requests; print(requests.__version__)"




# Name: SAGAR KUMAR MISHRA - 2024DC04006 - 40%
# Name: ROHITH CHOWDHARY TURLAPATI - 2024AC05851 - 30%
# Name: SABIKA QIZILBASH . - 2024DC04267 - 30%



import requests
import json
import time

# === Replace these ===
workspace_name = "synw-cta-0001-tst-cr"  # your workspace name
pipeline_name = "PL_Tst_Datahub_con"
subscription_id = "your-subscription-id"  # from Azure portal
resource_group = "your-resource-group"

# Synapse dev endpoint (find in Synapse Studio URL or portal)
synapse_endpoint = f"https://{workspace_name}.dev.azuresynapse.net"

# API version
api_version = "2020-12-01"

# Trigger URL
trigger_url = f"{synapse_endpoint}/pipelines/{pipeline_name}/createRun?api-version={api_version}"

# Headers - use managed identity if possible (Synapse notebook identity)
headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer " + mssparkutils.credentials.getToken("https://dev.azuresynapse.net/.default")  # AAD token
}

# Optional parameters if your pipeline has them
body = {}  # e.g. {"param1": "value1"}

try:
    response = requests.post(trigger_url, headers=headers, json=body)
    if response.status_code in [200, 202]:
        run_id = response.json().get("runId")
        print(f"Pipeline triggered! Run ID: {run_id}")
        
        # Simple status poll (get run status)
        status_url = f"{synapse_endpoint}/pipelineruns/{run_id}?api-version={api_version}"
        status = "InProgress"
        for _ in range(30):
            time.sleep(10)
            status_resp = requests.get(status_url, headers=headers)
            if status_resp.status_code == 200:
                status = status_resp.json().get("status")
                print(f"Status: {status}")
                if status not in ["InProgress", "Queued"]:
                    break
        
        if status == "Succeeded":
            print("Success! Check Monitor tab for response body.")
        else:
            print(f"Failed with status: {status}")
    else:
        print(f"Trigger failed: {response.status_code} - {response.text}")
except Exception as e:
    print("Error:", str(e))
-----
Perfect ‚Äî now we have **everything**.
I‚Äôll explain this **like a story**, then give you **exact notebook code** you can run **as-is**.

---

## üß† The story (layman, honest)

1. **Your DataHub URL is NOT public**

   * That‚Äôs why:

     * Browser ‚ùå sometimes
     * Local CMD / Notepad++ ‚ùå always
     * DNS error ‚ùå
   * This is **normal** for private/internal services.

2. **Your Synapse works because**

   * You are using **SelfHostedIntegrationRuntime**
   * That IR sits **inside Allianz network**
   * So DNS + routing works there ‚úÖ

3. **Linked Service = the ONLY bridge**

   * You **cannot** magically use Linked Service from local Python
   * You **must** run code **inside Synapse notebook**
   * Linked Service handles:

     * Network
     * DNS
     * Routing

4. **Your Linked Service is correct**

   * Name: `Datahub`
   * Type: `REST`
   * Base URL: `https://dhub-int.cta.allianz`
   * Auth: `Anonymous`
   * IR: `SelfHostedIntegrationRuntime`

üëâ So the solution is **Notebook ‚Üí read LS ‚Üí call API**

---

## ‚úÖ What WILL work (final architecture)

```
Synapse Notebook
   ‚Üì
mssparkutils.credentials (Linked Service)
   ‚Üì
SelfHosted IR (network + DNS)
   ‚Üì
https://dhub-int.cta.allianz
```

---

## üß™ FINAL working Synapse Notebook code (copy‚Äìpaste)

### üîπ Cell 1 ‚Äî Resolve Linked Service base URL

```python
from notebookutils import mssparkutils

# Get linked service details
ls_name = "Datahub"
creds = mssparkutils.credentials.getConnectionStringOrCreds(ls_name)

base_url = creds["url"]  # comes from linked service Base URL
print("Base URL from Linked Service:", base_url)
```

‚úÖ Expected output:

```
Base URL from Linked Service: https://dhub-int.cta.allianz
```

---

### üîπ Cell 2 ‚Äî Simple health/API test (NO pipeline, pure code)

```python
import requests

endpoint = "/actuator/health"   # simple safe endpoint
url = base_url + endpoint

print("Calling:", url)

response = requests.get(
    url,
    timeout=30,
    verify=False   # internal certs, common in corp env
)

print("Status code:", response.status_code)
print("Response:")
print(response.text)
```

---

## üßæ How to read the result

### ‚úÖ **These mean SUCCESS**

* `200` ‚Üí API is up
* `401 / 403` ‚Üí Network OK, auth needed
* `503` ‚Üí API reached, service issue (not your problem)

### ‚ùå **These mean config issue**

* `NameResolutionError` ‚Üí wrong IR / not using LS
* Timeout ‚Üí firewall / backend down

---

## üö´ What NOT to do (important)

‚ùå Do **NOT** try:

```python
requests.get("https://dhub-int.cta.allianz")
```

(from local machine or without LS)

‚ùå Do **NOT** use:

```text
@linkedService().BaseUrl
```

(This works only in pipelines, NOT notebooks)

---

## ‚úÖ Why your earlier Web Activity showed 503

That was **GOOD news** üëç
It means:

* DNS ‚úî
* Network ‚úî
* Endpoint ‚úî
* Only backend was temporarily unavailable

---

## üß© Next (only if you want to SEND data)

Once health works, sending data is just:

```python
requests.post(
    base_url + "/api/v1/ingestion",
    json=payload,
    headers={"Content-Type": "application/json"},
    verify=False
)
```

---

## üîö Final truth (clear & direct)

* ‚ùå Local Python will **never** work
* ‚ùå Notepad++ is irrelevant here
* ‚úÖ Synapse Notebook + Linked Service = correct way
* ‚úÖ Your setup is **already correct**

If you want, next I can:

* Add **payload example**
* Add **retry + logging**
* Help you write **JIRA update in 3 lines**



Got it üëç ‚Äî here are **3 short messages**, **only about today‚Äôs work**, written clean and technical, ready to send **one by one** on Teams.

---

**Message 1**
Today I tested DataHub connectivity from Synapse notebooks using Python APIs. Direct calls to `https://dhub-int.cta.allianz` failed with DNS/NameResolution errors, even though the URL is accessible in the browser.

---

**Message 2**
I then created a REST Linked Service in Synapse with the DataHub base URL (Anonymous auth, AutoResolve/SelfHosted IR) and attempted to access it from a notebook using `mssparkutils.credentials.getConnectionStringOrCreds`. This failed because Synapse notebooks do not support SelfHosted/interactive authentication for REST linked services.

---

**Message 3**
As of today‚Äôs findings, notebook-based API testing is blocked without a non-interactive auth mechanism (SPN/token/API key) and proper private endpoint/DNS support for Synapse. Next step is to align on the supported connectivity/auth approach from the DataHub side.
